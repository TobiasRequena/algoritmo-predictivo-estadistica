# ENTRENAMIENTO DE MODELOS PREDICTIVOS

from sklearn.linear_model import LinearRegression
from sklearn.tree import DecisionTreeRegressor, plot_tree
from sklearn.metrics import r2_score, mean_absolute_error
import matplotlib.pyplot as plt

def train_linear_model(X_train, X_test, y_train, y_test):
    """Entrena un modelo de regresiÃ³n lineal"""
    print("\nğŸ“ˆ Entrenando modelo: RegresiÃ³n Lineal...")

    model = LinearRegression()
    model.fit(X_train, y_train)
    y_pred = model.predict(X_test)

    r2 = r2_score(y_test, y_pred)
    mae = mean_absolute_error(y_test, y_pred)

    print(f"   â†’ RÂ²: {r2:.3f}, MAE: {mae:.3f}")
    return model, (r2, mae)


def train_tree_model(X_train, X_test, y_train, y_test):
    """Entrena un modelo de Ã¡rbol de decisiÃ³n"""
    print("\nğŸŒ³ Entrenando modelo: Ãrbol de DecisiÃ³n...")

    model = DecisionTreeRegressor(max_depth=3, random_state=42)
    model.fit(X_train, y_train)
    y_pred = model.predict(X_test)

    r2 = r2_score(y_test, y_pred)
    mae = mean_absolute_error(y_test, y_pred)

    print(f"   â†’ RÂ²: {r2:.3f}, MAE: {mae:.3f}")

    # ğŸ” Mostrar las caracterÃ­sticas mÃ¡s importantes
    importances = sorted(
        zip(X_train.columns, model.feature_importances_),
        key=lambda x: x[1],
        reverse=True
    )
    print("\nğŸ” Variables mÃ¡s importantes:")
    for feature, importance in importances[:10]:
        print(f"   {feature:<25} {importance:.3f}")

    # ğŸŒ³ VisualizaciÃ³n del Ã¡rbol (solo si el dataset no es muy grande)
    plt.figure(figsize=(16, 10))
    plot_tree(
        model,
        filled=True,
        feature_names=X_train.columns,
        rounded=True,
        fontsize=8
    )
    plt.title("Ãrbol de DecisiÃ³n â€“ PredicciÃ³n de precios de autos")
    plt.show()

    return model, (r2, mae)
